# SpaceClip üöÄ

**Transform your podcasts, videos, and X Spaces into viral clips with AI**

SpaceClip is a local-first, privacy-focused media clipping platform that uses AI to identify highlights, generate transcriptions, and create platform-optimized content.

## Features

- üìÅ **Multi-source Input**: Upload videos, audio files, or paste URLs from X Spaces, YouTube
- ü§ñ **AI-Powered**: Local AI processing with Ollama for highlight detection
- üìù **Auto-Transcription**: Whisper-powered transcription with speaker detection
- üé® **Audiogram Generation**: Beautiful waveform visualizations
- üì± **Multi-Platform Export**: One-click optimization for Instagram, TikTok, LinkedIn, YouTube Shorts

## Architecture

```
spaceclip/
‚îú‚îÄ‚îÄ frontend/          # Next.js 14 web application
‚îú‚îÄ‚îÄ backend/           # Python FastAPI server
‚îÇ   ‚îú‚îÄ‚îÄ services/      # Core processing services
‚îÇ   ‚îú‚îÄ‚îÄ api/           # API routes
‚îÇ   ‚îî‚îÄ‚îÄ models/        # Data models
‚îî‚îÄ‚îÄ shared/            # Shared types and utilities
```

## ‚ö†Ô∏è Authentication System Directive

**IMPORTANT: SpaceClip uses an opaque session-token authentication system.**

- Session tokens are stored in the database (`sessions` table)
- Backend verifies tokens by DB lookups, **NOT** by cryptographic claims
- Tokens are generated randomly and validated only server-side

**Do NOT replace the existing session-token system with JWT-based login.**
**Do NOT remove or bypass the sessions table.**
**Do NOT introduce stateless authentication for primary sign-in.**

JWTs may ONLY be introduced later as:
- Optional, separate authentication for enterprise SSO (Google, Azure, Okta, etc.)
- Short-lived access tokens layered on top of existing sessions
- Verification-only tokens issued by external IdPs

**Do NOT convert SpaceClip's internal auth system to JWTs.**
**Opaque DB-backed sessions remain the source of truth.**

See [`docs/AUTH_SYSTEM.md`](docs/AUTH_SYSTEM.md) for detailed architecture documentation.

## Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- FFmpeg
- Ollama (with llama3.2 or similar model)

### Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt
uvicorn main:app --reload
```

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

### Ollama Setup

```bash
# Install Ollama from https://ollama.ai
ollama pull llama3.2
ollama serve
```

## Starting and Stopping Servers

### Start Servers

**Option 1: Use the dev script (Recommended)**
```bash
./scripts/dev.sh
```
This starts both backend and frontend automatically. Press `Ctrl+C` to stop all services.

**Option 2: Start manually**

Backend (in one terminal):
```bash
cd backend
source venv/bin/activate
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Frontend (in another terminal):
```bash
cd frontend
npm run dev
```

### Stop Servers

**If using the dev script:**
- Press `Ctrl+C` in the terminal running the script

**If running manually:**
- Press `Ctrl+C` in each terminal, or
- Kill processes by port:
```bash
# Kill both backend and frontend
lsof -ti:8000,3000 | xargs kill -9

# Or use pkill
pkill -f "uvicorn main:app" && pkill -f "npm run dev"
```

## Environment Variables

Create `.env` files in both `frontend/` and `backend/` directories:

### Backend `.env`
```
OLLAMA_HOST=http://localhost:11434
WHISPER_MODEL=base
UPLOAD_DIR=./uploads
OUTPUT_DIR=./outputs
```

### Frontend `.env.local`
```
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## License

MIT





